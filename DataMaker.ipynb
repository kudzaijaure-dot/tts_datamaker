{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TTS Datamaker**\n",
        "\n",
        "This repository offers a way to make personalized dataset for model creation using the LJSpeech format. Run all the scripts below after reading the instructions on [the TTS Readme](https://github.com/kudzaijaure-dot/tts_datamaker)"
      ],
      "metadata": {
        "id": "HlJAY9MXn61p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kudzaijaure-dot/tts_datamaker.git \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eauFU_Ozoqs9",
        "outputId": "274b4139-ae3e-4197-cf9f-560a2c2e5719"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tts_datamaker'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 80 (delta 41), reused 69 (delta 36), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd tts_datamaker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrcI2JaAtZsO",
        "outputId": "b2b2e86a-22e0-4e36-82bd-b732e906acaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tts_datamaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic5H0iORtT1J",
        "outputId": "66af3bcb-0b8b-49e1-ae92-414d701ed4bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.3.5)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting requests>=2.26.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 4)) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition->-r requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition->-r requirements.txt (line 3)) (2.10)\n",
            "Installing collected packages: pydub, requests, pytube, ffmpeg-python, SpeechRecognition\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed SpeechRecognition-3.9.0 ffmpeg-python-0.2.0 pydub-0.25.1 pytube-12.1.2 requests-2.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Large Audios by either python command or gdwon command**"
      ],
      "metadata": {
        "id": "VKj5G4hdpF71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python audio_download.py --video_link https://www.youtube.com/watch?v=BbqqSuxyLc0 --speaker_name karan\n",
        "!cd main_audio && gdown https://drive.google.com/uc?id=None\n",
        "!mkdir /content/tts_train_dir/\n",
        "!mkdir /content/tts_train_dir/karan/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY696ZywpRu0",
        "outputId": "8cccaa3b-1e10-4676-8fe4-861d3b4d2d37"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=None \n",
            "\n",
            "mkdir: cannot create directory ‘/content/tts_train_dir/’: File exists\n",
            "mkdir: cannot create directory ‘/content/tts_train_dir/karan/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Segment Extraction**"
      ],
      "metadata": {
        "id": "ZRVZZax3poVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from extract_segment import SplitWavAudioMubin\n",
        "\n",
        "download_folder=\"main_audio\" #Not to change\n",
        "video_filename=\"karan.mp4\"   # Change as per as audio name\n",
        "output_folder_split=\"/content/tts_train_dir/karan/wavs\"  \n",
        "\n",
        "\n",
        "spliter=SplitWavAudioMubin(download_folder,video_filename,output_folder_split)\n",
        "spliter.multiple_split(10)"
      ],
      "metadata": {
        "id": "ubxTt3OQpvzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Extraction**"
      ],
      "metadata": {
        "id": "EVAaeirzq_Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from extract_text import text_extraction\n",
        "\n",
        "path_to_audio_split=output_folder_split\n",
        "output_folder=\"/content/tts_train_dir/karan\" \n",
        "output_file= \"metadata.txt\"\n",
        "\n",
        "et=text_extraction(path_to_audio_split)\n",
        "et.extract(output_folder,output_file)"
      ],
      "metadata": {
        "id": "uYqo72BcrFbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Output Dataset**"
      ],
      "metadata": {
        "id": "Sq-lO1bDsEus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/tts_train_dir/karan.zip /content/tts_train_dir/karan\n",
        "from google.colab import files\n",
        "files.download('/content/tts_train_dir/karan.zip')"
      ],
      "metadata": {
        "id": "22sjsycIsI6s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}